{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.plotting_context('poster')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training datasets\n",
    "variants and text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v = pd.read_csv('training_variants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_t = pd.read_csv('training_text', sep='\\|\\|',skiprows=1, engine='python', names=[\"ID\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train_v,train_t, on = ['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing datasets\n",
    "variant and text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_v = pd.read_csv('test_variants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_t = pd.read_csv('test_text', sep='\\|\\|',skiprows=1, engine='python', names=[\"ID\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test_v,test_t, on = ['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=1, ignore_index=True, keys=['train', 'test'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variants\n",
    "Classifies variations into common types and standardizes their name. The order of commands in the fuc matters because deletions & insertions can happen simulteneously but coding is inconsistent. Testing: func is coding variations accurately. We might want to change the Fussion expression (\"fs\") because it could be problematic with new data, but hacky version works for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var_recode(data, colname):\n",
    "    recoded_colname = colname + '_recoded'\n",
    "    #recode substitutions\n",
    "    data[recoded_colname] = data[colname].str.replace('^[A-Z]\\d+[A-Z\\*]$|^(null)\\d+[A-Z\\*]$', 'Substitution')\n",
    "    #recode deletions\n",
    "    data.loc[data[colname].str.contains('del|silencing|hypermethylation', case=False), recoded_colname] = 'Deletion'\n",
    "    #recode insertions\n",
    "    data.loc[data[colname].str.contains('ins', case=False) , recoded_colname] = 'Insertion'\n",
    "    #recode deletions/insertions\n",
    "    data.loc[(data[colname].str.contains('del', case=False) & \n",
    "              data[colname].str.contains('ins', case=False)), recoded_colname] = 'InDel'\n",
    "    #recode truncations\n",
    "    data.loc[data[colname].str.contains('trunc', case=False), recoded_colname] = 'Truncation'\n",
    "    #recode duplications\n",
    "    data.loc[data[colname].str.contains('dup', case=False) , recoded_colname] = 'Duplication'\n",
    "    #recode fusions \n",
    "    data.loc[data[colname].str.contains('fusion|fs', case=False), recoded_colname] = 'Fusion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_recode(df, 'Variation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genes\n",
    "quick function to calculate gene frequency for a grouping variable 1) count of unique genes 2) total number of genes per group (similar to group frequency) 3) most frequent gene in each group 4) proportional frequency of gene accounting for size of group 5) reset index for easier plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genefreq(data, group):\n",
    "    newdf = data.groupby(group).agg('Gene': pd.Series.nunique)\n",
    "    newdf['Gene_total'] = data.groupby(group)['Gene'].count()\n",
    "    newdf['Gene_most_frequent'] = data.groupby(group)['Gene'].agg(lambda x: x.value_counts().idxmax())\n",
    "    newdf['Gene_most_frequent_count'] = data.groupby(group)['Gene'].agg(lambda x: x.value_counts().max())\n",
    "    newdf['Gene_p_unique'] = newdf['Gene']/newdf['Gene_total']\n",
    "    newdf['Gene_p_most_frequent'] = newdf['Gene_most_frequent_count']/var_grp['Gene_total']\n",
    "    newdf.reset_index(inplace=True)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genefreq(df, 'Variation_recoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word count per entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'Word_count']  = df[\"Text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, 3321):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find frequent words (from SK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(corpus)\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "h = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "h.reset_index(inplace = True)\n",
    "h.sort_values('frequency',ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = 'mutat, cancer, patient, protein, express, tumor, variant, kinase, domain, brca1, egfr, activation, ras, p53, exon, growth, clinical, signaling, function, pten, phospharylation, residue, resistance, raf, pathway, alk, disease, receptor, missense, breast, braf, inhibit, lung, tyrosine, acid, induce, survival, proliferation, akt, imatinib, fusion, oncogenic, transcription, deleterous, flt3, melanoma, somatic, gefitinib, brct, myc, amplification, genomic, pathogenic, benign, p21, phosphatase, sp3b1, bat3'.split(', ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find frequency of top words in each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count(df, words):    \n",
    "    for word in words:\n",
    "        w =[]\n",
    "        for row in df['text']:\n",
    "            n = row.lower().count(word)\n",
    "            w.append(n)\n",
    "        df[word] = w\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_text = word_count(df, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"bag of words\" from MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(corpus)\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "df=pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "df.sort_values('frequency', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word count per entry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
